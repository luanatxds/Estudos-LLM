{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/YgcNTCydDTfU/mIiXuZz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luanatxds/Estudos-LLM/blob/main/Chatbot_facebook_blenderbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala bibliotecas necessárias\n",
        "!pip install transformers gradio torch sentencepiece matplotlib pydantic --quiet\n"
      ],
      "metadata": {
        "id": "tdRqTP-A6-Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "from pydantic import BaseModel\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import gradio as gr\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "NMvb5Cim6_NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo para extração de dados em JSON (exemplo simples)\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "pipe = AutoModelForCausalLM.from_pretrained(pipe_model_name, torch_dtype=\"auto\", device_map=\"auto\")\n",
        "tokenizer_pipe = AutoTokenizer.from_pretrained(pipe_model_name)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "# Modelo para chatbot via Gradio\n",
        "chat_model_name = \"facebook/blenderbot-400M-distill\"\n",
        "chat_model = AutoModelForSeq2SeqLM.from_pretrained(chat_model_name)\n",
        "chat_tokenizer = AutoTokenizer.from_pretrained(chat_model_name)"
      ],
      "metadata": {
        "id": "drU1Dtsw7Ad7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    inputs = chat_tokenizer.encode(user_input, return_tensors=\"pt\")\n",
        "    outputs = chat_model.generate(inputs, max_new_tokens=150)\n",
        "    response = chat_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_response,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Digite sua mensagem aqui...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Chatbot com Transformers\",\n",
        "    description=\"Chat interativo usando facebook/blenderbot-400M-distill\"\n",
        ")\n",
        "\n",
        "# Para rodar: iface.launch()\n"
      ],
      "metadata": {
        "id": "7v9afWBA7Fe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch()"
      ],
      "metadata": {
        "id": "UkdWGmZu7Ig7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse chatbot é muito especial, aqui estão minhas respostas favoritas dele\n",
        "---\n",
        "- do you have some setting for behaving?\n",
        "- Not really. I just don't know what to do. I don't want to get in trouble\n",
        "---\n",
        "- Do you have a personality?\n",
        "-   I think I do, but I'm not sure if that's a good or bad thing.\n",
        "---\n",
        "- How old are you?\n",
        "-  I am in my early twenties. I am not sure what to do with myself.\n"
      ],
      "metadata": {
        "id": "sp_6k4DvA6ht"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8LWjhgqmBH2D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}